{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle detection using cv\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load files from both class -> search for function\n",
    "# preprocess -> normalize, shuffle\n",
    "# implement sliding windows\n",
    "# implement hog, color\n",
    "# combine and normalize features\n",
    "# implement heatmap\n",
    "# implement tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import random\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.externals import joblib\n",
    "from VehicleFinder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size cars: 8792 non-cars: 8968\n"
     ]
    }
   ],
   "source": [
    "cars = glob.glob('./vehicles/*/*.png')\n",
    "notcars = glob.glob('./non-vehicles/*/*.png')\n",
    "\n",
    "print('data size cars: {} non-cars: {}'.format(len(cars), len(notcars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finder = VehicleFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trivus/anaconda3/envs/ml/lib/python3.6/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.32 sec to train SVC\n",
      "Test accuracy of SVC: 0.9828\n",
      "Predicts:  [ 1.  0.  1.  0.  1.  0.  1.  1.  0.  1.]\n",
      "Truth:  [ 1.  0.  1.  0.  1.  0.  1.  1.  0.  1.]\n",
      "0.0014 sec to predict 10 samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./finder']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.train_from_path(cars, notcars)\n",
    "joblib.dump(finder, './finder')\n",
    "joblib.dump(finder.clf, './clf')\n",
    "joblib.dump(finder.scaler, './scaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './clf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-055e63c7a2da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./clf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./scaler'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './clf'"
     ]
    }
   ],
   "source": [
    "finder.clf = joblib.load('./clf')\n",
    "finder.scaler = joblib.load('./scaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4896,)\n"
     ]
    }
   ],
   "source": [
    "print(finder.scaler.scale_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trivus/anaconda3/envs/ml/lib/python3.6/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'ravel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d3e146316317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./test_images/*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_cars_from_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Class/CarND-Vehicle-Detection/VehicleFinder.py\u001b[0m in \u001b[0;36mfind_cars_from_img\u001b[0;34m(self, img, ystart, ystop, scale)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mhog_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mch_hog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                     \u001b[0mhog_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch_hog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_window\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_window\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_window\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_window\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mxleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_window\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhog_pix_per_cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'ravel'"
     ]
    }
   ],
   "source": [
    "test_image = glob.glob('./test_images/*.jpg')\n",
    "image = mpimg.imread(test_image[0])\n",
    "finder.find_cars_from_img(image, 300, 600, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize few samples\n",
    "def show_samples_path(path_list, number=10):\n",
    "    f, axs = plt.subplots(number // 5, 5, figsize=(20,number))    \n",
    "    show_list = random.sample(path_list, number)\n",
    "    for i in range(number):\n",
    "        img = mpimg.imread(show_list[i])\n",
    "        axs[i//5, i % 5].imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_samples_path(cars, 10)\n",
    "show_samples_path(notcars, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def color_code(cspace):\n",
    "    \"\"\"\n",
    "    get cv2 colorspace name to convert from RGB\n",
    "    \"\"\"\n",
    "    if cspace == 'HSV':\n",
    "        return cv2.COLOR_RGB2HSV\n",
    "    elif cspace == 'LUV':\n",
    "        return cv2.COLOR_RGB2LUV\n",
    "    elif cspace == 'HLS':\n",
    "        return cv2.COLOR_RGB2HLS\n",
    "    elif cspace == 'YUV':\n",
    "        return cv2.COLOR_RGB2YUV\n",
    "    else:\n",
    "        raise Exception('Unavailable color space.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32,32)):\n",
    "    features = cv2.resize(img, size).ravel()\n",
    "    return features\n",
    "\n",
    "\n",
    "def color_hist(img, nbins=32, channel=None, bins_range=(0,256)):    \n",
    "    if channel is None:\n",
    "        chan1 = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "        chan2 = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "        chan3 = np.histogram(img[:,:,2], bins=nbins, range=bins_range)        \n",
    "        hist_features = np.concatenate((chan1[0], chan2[0], chan3[0]))    \n",
    "    elif type(channel) == int and 0 < channel < img.shape[2]:\n",
    "        hist_features = np.histogram(img[:,:,channel], bins=nbins)[0]\n",
    "    else:\n",
    "        raise Exception('Incorrect channel number')\n",
    "    return hist_features\n",
    "\n",
    "\n",
    "def get_hog(img, orient=9, pix_per_cell=8, cell_per_block=2, vis=False, feature_vec=True):\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "\n",
    "def extract_feature(img, color_space='RGB', orient=9, hog_channel=None, \n",
    "                    pix_per_cell=8, cell_per_block=2, channel=None, spatial_size=(32,32), hist_bins=32, hist_range=(0,256)):    \n",
    "    \"\"\"\n",
    "    Extract features from single image\n",
    "    \"\"\"    \n",
    "    if color_space != 'RGB':\n",
    "        feature_image = cv2.cvtColor(img, color_code(color_space))        \n",
    "    else: feature_image = np.copy(img)    \n",
    "        \n",
    "    spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "    hist_features = color_hist(feature_image, channel=channel, nbins=hist_bins, bins_range=hist_range)\n",
    "    feature_image = feature_image.astype(np.float32) / 255\n",
    "    if hog_channel is None:\n",
    "        hog_features = []\n",
    "        for channel in range(feature_image.shape[2]):\n",
    "            hog_features.append(get_hog(feature_image[..., channel], orient, pix_per_cell,\n",
    "                                       cell_per_block, vis=False, feature_vec=True))\n",
    "        hog_features = np.ravel(hog_features)\n",
    "    else:\n",
    "        hog_features = get_hog(feature_image[...,hog_channel], orient, pix_per_cell,\n",
    "                              cell_per_block, vis=False, feature_vec=True)\n",
    "    return np.concatenate([spatial_features, hist_features, hog_features])\n",
    "\n",
    "\n",
    "def dir_extract_feature(img_dir, color_space='RGB', orient=9, hog_channel=None, \n",
    "                    pix_per_cell=8, cell_per_block=2, channel=None, spatial_size=(32,32), hist_bins=32, hist_range=(0,256)):  \n",
    "    \"\"\"\n",
    "    Extract features from image directory\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for img_path in img_dir:        \n",
    "        img = mpimg.imread(img_path)\n",
    "        if img_path.split('.')[-1] == 'png':\n",
    "            img = img.astype(np.float32) * 255        \n",
    "        features.append(extract_feature(img, cspace=cspace, orient=orient, hog_channel=hog_channel, \n",
    "                    pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, channel=channel, spatial_size=spatial_size, hist_bins=hist_bins, hist_range=hist_range))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize hog features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,3), sharex=True, sharey=True)\n",
    "feature, hog_img = get_hog(img[...,0], orient=9, pix_per_cell=8, cell_per_block=8, vis=True, feature_vec=False)\n",
    "img = mpimg.imread(cars[100])\n",
    "ax1.imshow(img)\n",
    "ax2.imshow(hog_img)\n",
    "plt.show()\n",
    "print (feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "car_features = dir_extract_feature(cars, cspace='YUV', hog_channel=0, spatial_size=(32,32), hist_bins=32, hist_range=(0,256))\n",
    "notcar_features = dir_extract_feature(notcars, cspace='YUV', hog_channel=0, spatial_size=(32,32), hist_bins=32, hist_range=(0,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "scaled_X = X_scaler.transform(X)\n",
    "car_ind = np.random.randint(0, len(cars))\n",
    "# Plot an example of raw and scaled features\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "plt.subplot(131)\n",
    "plt.imshow(mpimg.imread(cars[car_ind]))\n",
    "plt.title('Original Image')\n",
    "plt.subplot(132)\n",
    "plt.plot(X[car_ind])\n",
    "plt.title('Raw Features')\n",
    "plt.subplot(133)\n",
    "plt.plot(scaled_X[car_ind])\n",
    "plt.title('Normalized Features')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = LinearSVC()\n",
    "t = time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'sec to train SVC')\n",
    "print('Test accuracy of SVC: {}'.format(round(svc.score(X_test, y_test), 4)))\n",
    "t = time.time()\n",
    "n_predict = 10\n",
    "print('Predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('Truth: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'sec to predict {} samples'.format(n_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save classifier and scaler to disk\n",
    "joblib.dump(svc, './svc')\n",
    "joblib.dump(X_scaler, './scaler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image = glob.glob('./test_images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, boxes, color=(0,0,255), thick=6):\n",
    "    imcopy = np.copy(img)\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(imcopy, box[0], box[1], color, thick)\n",
    "    return imcopy\n",
    "\n",
    "def sliding_window(img, x_start_stop=[None, None], y_start_stop=[None,None], xy_window=(64, 64), xy_overlap=(.5,.5)):\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    \n",
    "    x_step = int(xy_window[0] * xy_overlap[0])\n",
    "    y_step = int(xy_window[1] * xy_overlap[1])\n",
    "    \n",
    "    window_list = []\n",
    "    for xi in range(x_start_stop[0], x_start_stop[1], x_step):\n",
    "        for yi in range(y_start_stop[0], y_start_stop[1], y_step):\n",
    "            window_list.append(((xi, yi), (xi+x_step, yi+y_step)))\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread(test_image[0])\n",
    "\n",
    "windows = sliding_window(image, xy_window=(128,128), xy_overlap=(.5,.5))\n",
    "window_img = draw_boxes(image, windows)\n",
    "plt.imshow(window_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function you will pass an image \n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "def search_windows(img, windows, clf, scaler, color_space='RGB', \n",
    "                    spatial_size=(32, 32), hist_bins=32, \n",
    "                    hist_range=(0, 256), orient=9, \n",
    "                    pix_per_cell=8, cell_per_block=2, \n",
    "                    hog_channel=0, spatial_feat=True, \n",
    "                    hist_feat=True, hog_feat=True):\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = extract_feature(test_img,  \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler,\n",
    "              orient, pix_per_cell, cell_per_block, spatial_size, hist_bins,\n",
    "              color_space = 'RGB'):\n",
    "    '''\n",
    "    Predict car positions more efficiently; calculate hog once.\n",
    "    '''\n",
    "    draw_img = np.copy(img)  \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    if color_space != 'RGB':\n",
    "        img_tosearch = cv2.cvtColor(img_tosearch, color_code(color_space))    \n",
    "    if scale != 1:\n",
    "        imshape = img_tosearch.shape\n",
    "        img_tosearch = cv2.resize(img_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = img_tosearch[:,:,0]\n",
    "    ch2 = img_tosearch[:,:,1]\n",
    "    ch3 = img_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "                \n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread(test_image[0])\n",
    "out_image = np.copy(image)\n",
    "windows = sliding_window(image)\n",
    "hot_windows = search_windows(image, windows, svc, X_scaler)\n",
    "window_img = draw_boxes(out_image, hot_windows)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.imshow(window_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
